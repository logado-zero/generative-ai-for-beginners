{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG) and Vector Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting getenv\n",
      "  Downloading getenv-0.2.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting openai==1.12.0\n",
      "  Downloading openai-1.12.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from openai==1.12.0) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from openai==1.12.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from openai==1.12.0) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from openai==1.12.0) (2.5.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from openai==1.12.0) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from openai==1.12.0) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from openai==1.12.0) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.12.0) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.12.0) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.12.0) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.12.0) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.12.0) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.12.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.12.0) (2.14.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from tqdm>4->openai==1.12.0) (0.4.6)\n",
      "Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
      "   ---------------------------------------- 0.0/226.7 kB ? eta -:--:--\n",
      "   ------- ------------------------------- 41.0/226.7 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  225.3/226.7 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 226.7/226.7 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading getenv-0.2.0-py3-none-any.whl (2.6 kB)\n",
      "Installing collected packages: getenv, openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.25.0\n",
      "    Uninstalling openai-1.25.0:\n",
      "      Successfully uninstalled openai-1.25.0\n",
      "Successfully installed getenv-0.2.0 openai-1.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install getenv openai==1.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import dotenv\n",
    "\n",
    "# import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our Knowledge base\n",
    "\n",
    "Creating a Azure Cosmos DB database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-cosmos\n",
      "  Downloading azure_cosmos-4.7.0-py3-none-any.whl.metadata (70 kB)\n",
      "     ---------------------------------------- 0.0/70.3 kB ? eta -:--:--\n",
      "     ----- ---------------------------------- 10.2/70.3 kB ? eta -:--:--\n",
      "     --------------------------------- ---- 61.4/70.3 kB 825.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 70.3/70.3 kB 769.6 kB/s eta 0:00:00\n",
      "Collecting azure-core>=1.25.1 (from azure-cosmos)\n",
      "  Downloading azure_core-1.30.2-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from azure-cosmos) (4.11.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from azure-core>=1.25.1->azure-cosmos) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from azure-core>=1.25.1->azure-cosmos) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.25.1->azure-cosmos) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.25.1->azure-cosmos) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.25.1->azure-cosmos) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\miniconda3\\envs\\ai4beg\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.25.1->azure-cosmos) (2024.6.2)\n",
      "Downloading azure_cosmos-4.7.0-py3-none-any.whl (252 kB)\n",
      "   ---------------------------------------- 0.0/252.1 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 204.8/252.1 kB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 252.1/252.1 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading azure_core-1.30.2-py3-none-any.whl (194 kB)\n",
      "   ---------------------------------------- 0.0/194.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 194.3/194.3 kB ? eta 0:00:00\n",
      "Installing collected packages: azure-core, azure-cosmos\n",
      "Successfully installed azure-core-1.30.2 azure-cosmos-4.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-cosmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create your cosmoss db on Azure CLI using the following commands\n",
    "## az login\n",
    "## az group create -n <resource-group-name> -l <location>\n",
    "## az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>\n",
    "## az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>\n",
    "\n",
    "## Once done navigate to data explorer and create a new database and a new container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cosmos import CosmosClient\n",
    "\n",
    "# Initialize Cosmos Client\n",
    "url = os.getenv('COSMOS_DB_ENDPOINT')\n",
    "key = os.getenv('COSMOS_DB_KEY')\n",
    "client = CosmosClient(url, credential=key)\n",
    "\n",
    "# Select database\n",
    "database_name = 'rag-cosmos-db'\n",
    "database = client.get_database_client(database_name)\n",
    "\n",
    "# Select container\n",
    "container_name = 'data'\n",
    "container = database.get_container_client(container_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/own_framework.md</td>\n",
       "      <td># Introduction to Neural Networks. Multi-Layer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/perceptron.md</td>\n",
       "      <td># Introduction to Neural Networks: Perceptron\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    path                                               text\n",
       "0     data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...\n",
       "1  data/own_framework.md  # Introduction to Neural Networks. Multi-Layer...\n",
       "2     data/perceptron.md  # Introduction to Neural Networks: Perceptron\\..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "df = pd.DataFrame(columns=['path', 'text'])\n",
    "\n",
    "\n",
    "# splitting our data into chunks\n",
    "data_paths= [\"data/frameworks.md\", \"data/own_framework.md\", \"data/perceptron.md\"]\n",
    "\n",
    "for path in data_paths:\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.read()\n",
    "\n",
    "    # Append the file path and text to the DataFrame\n",
    "    df = pd.concat([df,pd.DataFrame([{'path': path, 'text': file_content}])],ignore_index=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>[# Neural Network Frameworks As we have learne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/own_framework.md</td>\n",
       "      <td># Introduction to Neural Networks. Multi-Layer...</td>\n",
       "      <td>[# Introduction to Neural Networks. Multi-Laye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/perceptron.md</td>\n",
       "      <td># Introduction to Neural Networks: Perceptron\\...</td>\n",
       "      <td>[# Introduction to Neural Networks: Perceptron...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    path                                               text  \\\n",
       "0     data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "1  data/own_framework.md  # Introduction to Neural Networks. Multi-Layer...   \n",
       "2     data/perceptron.md  # Introduction to Neural Networks: Perceptron\\...   \n",
       "\n",
       "                                              chunks  \n",
       "0  [# Neural Network Frameworks As we have learne...  \n",
       "1  [# Introduction to Neural Networks. Multi-Laye...  \n",
       "2  [# Introduction to Neural Networks: Perceptron...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_text(text, max_length, min_length):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for word in words:\n",
    "        current_chunk.append(word)\n",
    "        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = []\n",
    "\n",
    "    # If the last chunk didn't reach the minimum length, add it anyway\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Assuming analyzed_df is a pandas DataFrame and 'output_content' is a column in that DataFrame\n",
    "splitted_df = df.copy()\n",
    "splitted_df['chunks'] = splitted_df['text'].apply(lambda x: split_text(x, 400, 300))\n",
    "\n",
    "splitted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td># Neural Network Frameworks As we have learned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>descent optimization While the `numpy` library...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>should give us the opportunity to compute grad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>those computations on GPUs is very important. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>API, there is also higher-level API, called Ke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 path                                               text  \\\n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "\n",
       "                                              chunks  \n",
       "0  # Neural Network Frameworks As we have learned...  \n",
       "0  descent optimization While the `numpy` library...  \n",
       "0  should give us the opportunity to compute grad...  \n",
       "0  those computations on GPUs is very important. ...  \n",
       "0  API, there is also higher-level API, called Ke...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'chunks' is a column of lists in the DataFrame splitted_df, we will split the chunks into different rows\n",
    "flattened_df = splitted_df.explode('chunks')\n",
    "\n",
    "flattened_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting our text to embeddings\n",
    "\n",
    "Converting out text  to embeddings, and storing them in our database in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "\n",
    "openai.api_type = \"openai\"\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text, model=\"text-embedding-ada-002\"):\n",
    "    # Create embeddings for each document chunk\n",
    "    embeddings = openai.embeddings.create(input = text, model=model).data[0].embedding\n",
    "    return embeddings\n",
    "\n",
    "#embeddings for the first chunk\n",
    "create_embeddings(flattened_df['chunks'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = create_embeddings(\"cat\")\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>chunks</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td># Neural Network Frameworks As we have learned...</td>\n",
       "      <td>[-0.017089299857616425, 0.002794487401843071, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>descent optimization While the `numpy` library...</td>\n",
       "      <td>[-0.01474149338901043, 0.0017059656092897058, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>should give us the opportunity to compute grad...</td>\n",
       "      <td>[-0.03686178848147392, -0.02068474516272545, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>those computations on GPUs is very important. ...</td>\n",
       "      <td>[-0.031714845448732376, -0.01109745167195797, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>API, there is also higher-level API, called Ke...</td>\n",
       "      <td>[-0.008053705096244812, -0.03333533555269241, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 path                                               text  \\\n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "\n",
       "                                              chunks  \\\n",
       "0  # Neural Network Frameworks As we have learned...   \n",
       "0  descent optimization While the `numpy` library...   \n",
       "0  should give us the opportunity to compute grad...   \n",
       "0  those computations on GPUs is very important. ...   \n",
       "0  API, there is also higher-level API, called Ke...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.017089299857616425, 0.002794487401843071, ...  \n",
       "0  [-0.01474149338901043, 0.0017059656092897058, ...  \n",
       "0  [-0.03686178848147392, -0.02068474516272545, 0...  \n",
       "0  [-0.031714845448732376, -0.01109745167195797, ...  \n",
       "0  [-0.008053705096244812, -0.03333533555269241, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create embeddings for the whole data chunks and store them in a list\n",
    "\n",
    "embeddings = []\n",
    "for chunk in flattened_df['chunks']:\n",
    "    embeddings.append(create_embeddings(chunk))\n",
    "\n",
    "# store the embeddings in the dataframe\n",
    "flattened_df['embeddings'] = embeddings\n",
    "\n",
    "flattened_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "\n",
    "Vector search and similiarity between our prompt and the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an search index and reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>chunks</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>indices</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td># Neural Network Frameworks As we have learned...</td>\n",
       "      <td>[-0.017089299857616425, 0.002794487401843071, ...</td>\n",
       "      <td>[0, 2, 11, 3, 1]</td>\n",
       "      <td>[0.0, 0.523271729080148, 0.5282808588281044, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>descent optimization While the `numpy` library...</td>\n",
       "      <td>[-0.01474149338901043, 0.0017059656092897058, ...</td>\n",
       "      <td>[1, 0, 32, 2, 50]</td>\n",
       "      <td>[0.0, 0.569985387825166, 0.5920245992435789, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>should give us the opportunity to compute grad...</td>\n",
       "      <td>[-0.03686178848147392, -0.02068474516272545, 0...</td>\n",
       "      <td>[2, 3, 0, 5, 1]</td>\n",
       "      <td>[0.0, 0.5056048476107072, 0.523271729080148, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>those computations on GPUs is very important. ...</td>\n",
       "      <td>[-0.031714845448732376, -0.01109745167195797, ...</td>\n",
       "      <td>[3, 2, 0, 10, 11]</td>\n",
       "      <td>[0.0, 0.5056048476107072, 0.5463271890300337, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>API, there is also higher-level API, called Ke...</td>\n",
       "      <td>[-0.008053705096244812, -0.03333533555269241, ...</td>\n",
       "      <td>[4, 12, 10, 8, 9]</td>\n",
       "      <td>[0.0, 0.5202010562661403, 0.5529406126323927, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 path                                               text  \\\n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "\n",
       "                                              chunks  \\\n",
       "0  # Neural Network Frameworks As we have learned...   \n",
       "0  descent optimization While the `numpy` library...   \n",
       "0  should give us the opportunity to compute grad...   \n",
       "0  those computations on GPUs is very important. ...   \n",
       "0  API, there is also higher-level API, called Ke...   \n",
       "\n",
       "                                          embeddings            indices  \\\n",
       "0  [-0.017089299857616425, 0.002794487401843071, ...   [0, 2, 11, 3, 1]   \n",
       "0  [-0.01474149338901043, 0.0017059656092897058, ...  [1, 0, 32, 2, 50]   \n",
       "0  [-0.03686178848147392, -0.02068474516272545, 0...    [2, 3, 0, 5, 1]   \n",
       "0  [-0.031714845448732376, -0.01109745167195797, ...  [3, 2, 0, 10, 11]   \n",
       "0  [-0.008053705096244812, -0.03333533555269241, ...  [4, 12, 10, 8, 9]   \n",
       "\n",
       "                                           distances  \n",
       "0  [0.0, 0.523271729080148, 0.5282808588281044, 0...  \n",
       "0  [0.0, 0.569985387825166, 0.5920245992435789, 0...  \n",
       "0  [0.0, 0.5056048476107072, 0.523271729080148, 0...  \n",
       "0  [0.0, 0.5056048476107072, 0.5463271890300337, ...  \n",
       "0  [0.0, 0.5202010562661403, 0.5529406126323927, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "embeddings = flattened_df['embeddings'].to_list()\n",
    "\n",
    "# Create the search index\n",
    "nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)\n",
    "\n",
    "# To query the index, you can use the kneighbors method\n",
    "distances, indices = nbrs.kneighbors(embeddings)\n",
    "\n",
    "# Store the indices and distances in the DataFrame\n",
    "flattened_df['indices'] = indices.tolist()\n",
    "flattened_df['distances'] = distances.tolist()\n",
    "\n",
    "flattened_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in our model, in which case the input vector would be a vector of size N. A perceptron is a **binary classification** model, i.e. it can distinguish between two classes of input data. We will assume that for each input vector x the output of our perceptron would be either +1 or -1, depending on the class.\n",
      "data/perceptron.md\n",
      "[0.0, 0.5277524698843057, 0.5361884317207419, 0.5441593827523529, 0.5534469152717095]\n",
      "# Introduction to Neural Networks: Perceptron One of the first attempts to implement something similar to a modern neural network was done by Frank Rosenblatt from Cornell Aeronautical Laboratory in 1957. It was a hardware implementation called \"Mark-1\", designed to recognize primitive geometric figures,\n",
      "data/perceptron.md\n",
      "[0.0, 0.45838413163887076, 0.5234371691387615, 0.5630872658767582, 0.5633781042370638]\n",
      "user to adjust the resistance of a circuit. > The New York Times wrote about perceptron at that time: *the embryo of an electronic computer that [the Navy] expects will be able to walk, talk, see, write, reproduce itself and be conscious of its existence.* ## Perceptron Model Suppose we have N features\n",
      "data/perceptron.md\n",
      "[0.0, 0.5234371691387615, 0.5441593827523529, 0.560792634712331, 0.5757146974264087]\n"
     ]
    }
   ],
   "source": [
    "# Your text question\n",
    "question = \"what is a perceptron?\"\n",
    "\n",
    "# Convert the question to a query vector\n",
    "query_vector = create_embeddings(question)  # You need to define this function\n",
    "\n",
    "# Find the most similar documents\n",
    "distances, indices = nbrs.kneighbors([query_vector])\n",
    "\n",
    "index = []\n",
    "# Print the most similar documents\n",
    "for i in range(3):\n",
    "    index = indices[0][i]\n",
    "    if index :\n",
    "        print(flattened_df['chunks'].iloc[index])\n",
    "        print(flattened_df['path'].iloc[index])\n",
    "        print(flattened_df['distances'].iloc[index])\n",
    "    else:\n",
    "        print(f\"Index {index} not found in DataFrame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together to answer a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in our model, in which case the input vector would be a vector of size N. A perceptron is a **binary classification** model, i.e. it can distinguish between two classes of input data. We will assume that for each input vector x the output of our perceptron would be either +1 or -1, depending on the class.', '# Introduction to Neural Networks: Perceptron One of the first attempts to implement something similar to a modern neural network was done by Frank Rosenblatt from Cornell Aeronautical Laboratory in 1957. It was a hardware implementation called \"Mark-1\", designed to recognize primitive geometric figures,', 'user to adjust the resistance of a circuit. > The New York Times wrote about perceptron at that time: *the embryo of an electronic computer that [the Navy] expects will be able to walk, talk, see, write, reproduce itself and be conscious of its existence.* ## Perceptron Model Suppose we have N features', \"and to continue learning - go to Perceptron notebook. Here's an interesting article about perceptrons as well. ## Assignment In this lesson, we have implemented a perceptron for binary classification task, and we have used it to classify between two handwritten digits. In this lab, you are asked to solve\", '# Introduction to Neural Networks. Multi-Layered Perceptron In the previous section, you learned about the simplest neural network model - one-layered perceptron, a linear two-class classification model. In this section we will extend this model into a more flexible framework, allowing us to: * perform', 'what is a perceptron?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='A perceptron is a type of artificial neuron or basic unit of a neural network that was developed in the 1950s. It takes multiple input signals, applies weights to these inputs, sums them up, and then passes the sum through an activation function to produce an output. Perceptrons are often used in single-layer neural networks for simple classification tasks.', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user_input = \"what is a perceptron?\"\n",
    "\n",
    "# def chatbot(user_input):\n",
    "#     # Convert the question to a query vector\n",
    "#     query_vector = create_embeddings(user_input)\n",
    "\n",
    "#     # Find the most similar documents\n",
    "#     distances, indices = nbrs.kneighbors([query_vector])\n",
    "\n",
    "#     # add documents to query  to provide context\n",
    "#     history = []\n",
    "#     for index in indices[0]:\n",
    "#         history.append(flattened_df['chunks'].iloc[index])\n",
    "\n",
    "#     # combine the history and the user input\n",
    "#     history.append(user_input)\n",
    "#     # create a message object\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are an AI assiatant that helps with AI questions.\"},\n",
    "#         {\"role\": \"user\", \"content\": history[-1]}\n",
    "#     ]\n",
    "\n",
    "#     # use chat completion to generate a response\n",
    "#     response = openai.chat.completions.create(\n",
    "#         model=\"gpt-3.5-turbo\",\n",
    "#         temperature=0.7,\n",
    "#         max_tokens=800,\n",
    "#         messages=messages\n",
    "#     )\n",
    "\n",
    "#     return response.choices[0].message\n",
    "\n",
    "# chatbot(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='A perceptron is a type of artificial neural network, specifically a single-layer neural network. It is one of the simplest forms of neural networks and is based on a mathematical model of a biological neuron. The perceptron takes several input values, applies weights to them, sums them up, and passes the result through an activation function to produce an output. It is commonly used for binary classification tasks and can be trained using algorithms such as the perceptron learning rule or gradient descent.', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"what is a perceptron?\"\n",
    "\n",
    "def chatbot(user_input):\n",
    "    # Convert the question to a query vector\n",
    "    query_vector = create_embeddings(user_input)\n",
    "\n",
    "    # Find the most similar documents\n",
    "    distances, indices = nbrs.kneighbors([query_vector])\n",
    "\n",
    "    # add documents to query  to provide context\n",
    "    history = []\n",
    "    for index in indices[0]:\n",
    "        history.append(flattened_df['chunks'].iloc[index])\n",
    "\n",
    "    # combine the history and the user input\n",
    "    prompt = \"\"\"You are an AI assiatant that helps with AI questions. Use the following pieces of retrieved context: {doc} \\n\\n\n",
    "    If you cannot find the answer from the pieces of context, just say that you don't know, don't try to make up an answer.\"\"\"\n",
    "\n",
    "    prompt.format(doc=\"\\n\".join(history))\n",
    "    # create a message object\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "\n",
    "    # use chat completion to generate a response\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0.7,\n",
    "        max_tokens=800,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message\n",
    "\n",
    "chatbot(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic example of how you can use Mean Average Precision (MAP) to evaluate the responses of your model based on their relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in our model, in which case the input vector would be a vector of size N. A perceptron is a **binary classification** model, i.e. it can distinguish between two classes of input data. We will assume that for each input vector x the output of our perceptron would be either +1 or -1, depending on the class.', '# Introduction to Neural Networks: Perceptron One of the first attempts to implement something similar to a modern neural network was done by Frank Rosenblatt from Cornell Aeronautical Laboratory in 1957. It was a hardware implementation called \"Mark-1\", designed to recognize primitive geometric figures,', 'user to adjust the resistance of a circuit. > The New York Times wrote about perceptron at that time: *the embryo of an electronic computer that [the Navy] expects will be able to walk, talk, see, write, reproduce itself and be conscious of its existence.* ## Perceptron Model Suppose we have N features', \"and to continue learning - go to Perceptron notebook. Here's an interesting article about perceptrons as well. ## Assignment In this lesson, we have implemented a perceptron for binary classification task, and we have used it to classify between two handwritten digits. In this lab, you are asked to solve\", '# Introduction to Neural Networks. Multi-Layered Perceptron In the previous section, you learned about the simplest neural network model - one-layered perceptron, a linear two-class classification model. In this section we will extend this model into a more flexible framework, allowing us to: * perform']\n",
      "What is a perceptron?\n",
      "A perceptron is a type of artificial neuron that is used in supervised learning. It takes multiple inputs, applies weights to them, sums them up, and then passes the result through an activation function to produce an output. The perceptron is the simplest form of a feedforward neural network and was the basis for the development of more complex neural network models.\n",
      "---------------\n",
      "[\"of Machine Learning Let's start with formalizing the Machine Learning problem. Suppose we have a training dataset **X** with labels **Y**, and we need to build a model *f* that will make most accurate predictions. The quality of predictions is measured by **Loss function** &lagran;. The following loss\", 'it. ## Review & Self Study Backpropagation is a common algorithm used in AI and ML, worth studying in more detail ## Assignment In this lab, you are asked to use the framework you constructed in this lesson to solve MNIST handwritten digit classification. * Instructions * Notebook', \"let's recap the notion of overfitting. # Overfitting Overfitting is an extremely important concept in machine learning, and it is very important to get it right! Consider the following problem of approximating 5 dots (represented by `x` on the graphs below): !linear | overfit -------------------------|--------------------------\", 'data. Because subset is taken randomly each time, such method is called **stochastic gradient descent** (SGD). ## Multi-Layered Perceptrons and Backpropagation One-layer network, as we have seen above, is capable of classifying linearly separable classes. To build a richer model, we can combine several', 'is the difference between overfitting and underfitting? ## Assignment In this lab, you are asked to solve two classification problems using single- and multi-layered fully-connected networks using PyTorch or TensorFlow.']\n",
      "What is machine learning?\n",
      "I'm sorry, but I need more context to provide a relevant answer.\n",
      "---------------\n",
      "['it. ## Review & Self Study Backpropagation is a common algorithm used in AI and ML, worth studying in more detail ## Assignment In this lab, you are asked to use the framework you constructed in this lesson to solve MNIST handwritten digit classification. * Instructions * Notebook', 'should give us the opportunity to compute gradients of *any expression* that we can define. Another important thing is to be able to perform computations on GPU, or any other specialized compute units, such as TPU. Deep neural network training requires *a lot* of computations, and to be able to parallelize', 'it is important to understand how neural networks work from the ground up, thus in the beginning we start by working with low-level API and tensors. However, if you want to get going fast and do not want to spend a lot of time on learning these details, you can skip those and go straight into high-level', 'data. Because subset is taken randomly each time, such method is called **stochastic gradient descent** (SGD). ## Multi-Layered Perceptrons and Backpropagation One-layer network, as we have seen above, is capable of classifying linearly separable classes. To build a richer model, we can combine several', 'is the difference between overfitting and underfitting? ## Assignment In this lab, you are asked to solve two classification problems using single- and multi-layered fully-connected networks using PyTorch or TensorFlow.']\n",
      "What is deep learning?\n",
      "Can you provide me with more context to better understand your question?\n",
      "---------------\n",
      "['# Introduction to Neural Networks: Perceptron One of the first attempts to implement something similar to a modern neural network was done by Frank Rosenblatt from Cornell Aeronautical Laboratory in 1957. It was a hardware implementation called \"Mark-1\", designed to recognize primitive geometric figures,', 'array, so the neural network had 400 inputs and one binary output. A simple network contained one neuron, also called a **threshold logic unit**. Neural network weights acted like potentiometers that required manual adjustment during the training phase. > ✅ A potentiometer is a device that allows the', '# Introduction to Neural Networks. Multi-Layered Perceptron In the previous section, you learned about the simplest neural network model - one-layered perceptron, a linear two-class classification model. In this section we will extend this model into a more flexible framework, allowing us to: * perform', 'it is important to understand how neural networks work from the ground up, thus in the beginning we start by working with low-level API and tensors. However, if you want to get going fast and do not want to spend a lot of time on learning these details, you can skip those and go straight into high-level', '# Neural Network Frameworks As we have learned already, to be able to train neural networks efficiently we need to do two things: * To operate on tensors, eg. to multiply, add, and compute some functions such as sigmoid or softmax * To compute gradients of all expressions, in order to perform gradient']\n",
      "What is a neural network?\n",
      "A neural network is a type of machine learning model inspired by the structure of the human brain. It consists of interconnected nodes, called neurons, organized in layers. Each neuron processes input data and passes the output to other neurons. Neural networks are used for tasks such as image and speech recognition, natural language processing, and playing games. Would you like to know more about how neural networks work or their applications?\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Define your test cases\n",
    "test_cases = [\n",
    "    {\n",
    "        \"query\": \"What is a perceptron?\",\n",
    "        \"relevant_responses\": [\"A perceptron is a type of artificial neuron.\", \"It's a binary classifier used in machine learning.\"],\n",
    "        \"irrelevant_responses\": [\"A perceptron is a type of fruit.\", \"It's a type of car.\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is machine learning?\",\n",
    "        \"relevant_responses\": [\"Machine learning is a method of data analysis that automates analytical model building.\", \"It's a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.\"],\n",
    "        \"irrelevant_responses\": [\"Machine learning is a type of fruit.\", \"It's a type of car.\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is deep learning?\",\n",
    "        \"relevant_responses\": [\"Deep learning is a subset of machine learning in artificial intelligence (AI) that has networks capable of learning unsupervised from data that is unstructured or unlabeled.\", \"It's a type of machine learning.\"],\n",
    "        \"irrelevant_responses\": [\"Deep learning is a type of fruit.\", \"It's a type of car.\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is a neural network?\",\n",
    "        \"relevant_responses\": [\"A neural network is a series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates.\", \"It's a type of machine learning.\"],\n",
    "        \"irrelevant_responses\": [\"A neural network is a type of fruit.\", \"It's a type of car.\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Initialize the total average precision\n",
    "total_average_precision = 0\n",
    "\n",
    "# Test the RAG application\n",
    "for test_case in test_cases:\n",
    "    query = test_case[\"query\"]\n",
    "    relevant_responses = test_case[\"relevant_responses\"]\n",
    "    irrelevant_responses = test_case[\"irrelevant_responses\"]\n",
    "\n",
    "    # Generate a response using your RAG application\n",
    "    response = chatbot(query) \n",
    "    print(query)\n",
    "    print(response.content)\n",
    "    print(\"---------------\")\n",
    "    # Create a list of all responses and a list of true binary labels\n",
    "    all_responses = relevant_responses + irrelevant_responses\n",
    "    true_labels = [1] * len(relevant_responses) + [0] * len(irrelevant_responses)\n",
    "\n",
    "    # Create a list of predicted scores based on whether the response is the generated response\n",
    "    predicted_scores = [1 if resp == response else 0 for resp in all_responses]\n",
    "\n",
    "    # Calculate the average precision for this query\n",
    "    average_precision = average_precision_score(true_labels, predicted_scores)\n",
    "\n",
    "    # Add the average precision to the total average precision\n",
    "    total_average_precision += average_precision\n",
    "\n",
    "# Calculate the mean average precision\n",
    "mean_average_precision = total_average_precision / len(test_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_average_precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
